{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7be5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3921a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2465b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "207ed3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    763\n",
       "1      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f1c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Oversampling - Class Distribution:\n",
      "Class\n",
      "0    763\n",
      "1    763\n",
      "Name: count, dtype: int64\n",
      "Total Sample Size: 1526\n",
      "New Synthetic Samples Created: 754\n",
      "All original records preserved and minority class duplicated/synthesized\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\bhati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\bhati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# Generating synthetic samples for minority class to balance the dataset...\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "smote_data = pd.DataFrame(X_smote, columns=X.columns)\n",
    "smote_data['Class'] = y_smote\n",
    "\n",
    "print(\"SMOTE Oversampling - Class Distribution:\")\n",
    "print(smote_data['Class'].value_counts())\n",
    "print(f\"Total Sample Size: {len(smote_data)}\")\n",
    "print(f\"New Synthetic Samples Created: {len(smote_data) - len(data)}\")\n",
    "print(f\"All original records preserved and minority class duplicated/synthesized\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c84e1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sampling - Class Distribution:\n",
      "Class\n",
      "0    51\n",
      "1    49\n",
      "Name: count, dtype: int64\n",
      "Sample Size: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Simple Random Sampling\n",
    "# Randomly select samples without replacement\n",
    "sample_size = 100\n",
    "random_sample = smote_data.sample(n=sample_size, random_state=202)\n",
    "print(\"Random Sampling - Class Distribution:\")\n",
    "print(random_sample['Class'].value_counts())\n",
    "print(f\"Sample Size: {len(random_sample)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b79b1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Systematic Sampling - Class Distribution:\n",
      "Class\n",
      "0    52\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "Sample Size: 102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Systematic Sampling\n",
    "# Select every kth sample\n",
    "k = len(smote_data) // 100  # Calculate interval\n",
    "systematic_sample = smote_data.iloc[::k]\n",
    "print(\"Systematic Sampling - Class Distribution:\")\n",
    "print(systematic_sample['Class'].value_counts())\n",
    "print(f\"Sample Size: {len(systematic_sample)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62320cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Sampling - Class Distribution:\n",
      "Class\n",
      "0    382\n",
      "1    382\n",
      "Name: count, dtype: int64\n",
      "Sample Size: 764\n",
      "Class 0 Percentage: 50.00%\n",
      "Class 1 Percentage: 50.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhati\\AppData\\Local\\Temp\\ipykernel_16612\\1947785878.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stratified_sample = smote_data.groupby('Class', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# 3. Stratified Sampling\n",
    "# Sample proportionally from each class (best for unbalanced data)\n",
    "stratified_sample = smote_data.groupby('Class', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.5, random_state=42)\n",
    ")\n",
    "print(\"Stratified Sampling - Class Distribution:\")\n",
    "print(stratified_sample['Class'].value_counts())\n",
    "print(f\"Sample Size: {len(stratified_sample)}\")\n",
    "print(f\"Class 0 Percentage: {len(stratified_sample[stratified_sample['Class'] == 0]) / len(stratified_sample) * 100:.2f}%\")\n",
    "print(f\"Class 1 Percentage: {len(stratified_sample[stratified_sample['Class'] == 1]) / len(stratified_sample) * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be7f39c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Sampling - Class Distribution:\n",
      "Class\n",
      "1    396\n",
      "0    297\n",
      "Name: count, dtype: int64\n",
      "Sample Size: 693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Cluster Sampling\n",
    "# Divide data into clusters and randomly select clusters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "smote_data['Cluster'] = kmeans.fit_predict(smote_data.drop('Class', axis=1))\n",
    "\n",
    "# Randomly select clusters\n",
    "selected_clusters = np.random.choice(n_clusters, size=3, replace=False)\n",
    "cluster_sample = smote_data[smote_data['Cluster'].isin(selected_clusters)].drop('Cluster', axis=1)\n",
    "\n",
    "print(\"Cluster Sampling - Class Distribution:\")\n",
    "print(cluster_sample['Class'].value_counts())\n",
    "print(f\"Sample Size: {len(cluster_sample)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3a0b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation (K-Fold) - Class Distribution per Fold:\n",
      "\n",
      "Fold 1:\n",
      "  Training Set Size: 1220, Test Set Size: 306\n",
      "  Training - Class 0: 620, Class 1: 600\n",
      "  Test - Class 0: 143, Class 1: 163\n",
      "\n",
      "Fold 2:\n",
      "  Training Set Size: 1221, Test Set Size: 305\n",
      "  Training - Class 0: 603, Class 1: 618\n",
      "  Test - Class 0: 160, Class 1: 145\n",
      "\n",
      "Fold 3:\n",
      "  Training Set Size: 1221, Test Set Size: 305\n",
      "  Training - Class 0: 603, Class 1: 618\n",
      "  Test - Class 0: 160, Class 1: 145\n",
      "\n",
      "Fold 4:\n",
      "  Training Set Size: 1221, Test Set Size: 305\n",
      "  Training - Class 0: 601, Class 1: 620\n",
      "  Test - Class 0: 162, Class 1: 143\n",
      "\n",
      "Fold 5:\n",
      "  Training Set Size: 1221, Test Set Size: 305\n",
      "  Training - Class 0: 625, Class 1: 596\n",
      "  Test - Class 0: 138, Class 1: 167\n"
     ]
    }
   ],
   "source": [
    "# 5. Cross-Validation (K-Fold Split)\n",
    "# Divide data into k-folds for validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_number = 1\n",
    "\n",
    "print(\"Cross-Validation (K-Fold) - Class Distribution per Fold:\")\n",
    "for train_idx, test_idx in kfold.split(smote_data):\n",
    "    train_fold = smote_data.iloc[train_idx]\n",
    "    test_fold = smote_data.iloc[test_idx]\n",
    "    print(f\"\\nFold {fold_number}:\")\n",
    "    print(f\"  Training Set Size: {len(train_fold)}, Test Set Size: {len(test_fold)}\")\n",
    "    print(f\"  Training - Class 0: {len(train_fold[train_fold['Class'] == 0])}, Class 1: {len(train_fold[train_fold['Class'] == 1])}\")\n",
    "    print(f\"  Test - Class 0: {len(test_fold[test_fold['Class'] == 0])}, Class 1: {len(test_fold[test_fold['Class'] == 1])}\")\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4a29083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrap Sampling - Class Distribution:\n",
      "Class\n",
      "1    58\n",
      "0    42\n",
      "Name: count, dtype: int64\n",
      "Sample Size: 100\n",
      "Unique records: 97\n",
      "\n",
      "Bootstrap Sampling allows repeated selection of the same records\n"
     ]
    }
   ],
   "source": [
    "# 6. Bootstrap Sampling\n",
    "# Sampling with replacement\n",
    "sample_size = 100\n",
    "bootstrap_sample = smote_data.sample(n=sample_size, replace=True, random_state=42)\n",
    "\n",
    "print(\"\\nBootstrap Sampling - Class Distribution:\")\n",
    "print(bootstrap_sample['Class'].value_counts())\n",
    "print(f\"Sample Size: {len(bootstrap_sample)}\")\n",
    "print(f\"Unique records: {len(bootstrap_sample.drop_duplicates())}\")\n",
    "print(\"\\nBootstrap Sampling allows repeated selection of the same records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, sensitivity_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 5 different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='rbf', random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store all samples\n",
    "samples = {\n",
    "    'Original Data': data,\n",
    "    'Random Sampling': random_sample,\n",
    "    'Systematic Sampling': systematic_sample,\n",
    "    'Stratified Sampling': stratified_sample,\n",
    "    'Cluster Sampling': cluster_sample,\n",
    "    'Bootstrap Sampling': bootstrap_sample,\n",
    "    'SMOTE Oversampling': smote_data\n",
    "}\n",
    "\n",
    "print(f\"Models to train: {list(models.keys())}\")\n",
    "print(f\"Samples available: {list(samples.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff58d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train model and calculate evaluation metrics\"\"\"\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    sensitivity = recall  # Sensitivity = Recall for binary classification\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "print(\"Training and evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30391860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate all models on all samples\n",
    "results_summary = {}\n",
    "\n",
    "for sample_name, sample_data in samples.items():\n",
    "    results_summary[sample_name] = {}\n",
    "    \n",
    "    # Prepare data (80% train, 20% test)\n",
    "    X = sample_data.drop('Class', axis=1)\n",
    "    y = sample_data['Class']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training Models on: {sample_name}\")\n",
    "    print(f\"Training Set Size: {len(X_train)}, Test Set Size: {len(X_test)}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        metrics = train_and_evaluate(model, X_train, X_test, y_train, y_test)\n",
    "        results_summary[sample_name][model_name] = metrics\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Accuracy:   {metrics['Accuracy']:.4f}\")\n",
    "        print(f\"  Precision:  {metrics['Precision']:.4f}\")\n",
    "        print(f\"  Recall:     {metrics['Recall']:.4f}\")\n",
    "        print(f\"  Sensitivity:{metrics['Sensitivity']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison tables\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL PERFORMANCE COMPARISON ACROSS ALL SAMPLING TECHNIQUES\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# For each metric, create a table\n",
    "metrics_list = ['Accuracy', 'Precision', 'Recall', 'Sensitivity']\n",
    "\n",
    "for metric in metrics_list:\n",
    "    print(f\"\\n{metric.upper()} SCORES:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    metric_data = []\n",
    "    for sample_name in samples.keys():\n",
    "        row = {'Sampling Method': sample_name}\n",
    "        for model_name in models.keys():\n",
    "            if sample_name in results_summary and model_name in results_summary[sample_name]:\n",
    "                row[model_name] = f\"{results_summary[sample_name][model_name][metric]:.4f}\"\n",
    "            else:\n",
    "                row[model_name] = \"N/A\"\n",
    "        metric_data.append(row)\n",
    "    \n",
    "    metric_df = pd.DataFrame(metric_data)\n",
    "    print(metric_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: Best performing combinations\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"BEST PERFORMING MODEL-SAMPLING COMBINATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for metric in metrics_list:\n",
    "    print(f\"\\nBest {metric} Score:\")\n",
    "    \n",
    "    best_score = 0\n",
    "    best_combo = None\n",
    "    \n",
    "    for sample_name in samples.keys():\n",
    "        for model_name in models.keys():\n",
    "            if sample_name in results_summary and model_name in results_summary[sample_name]:\n",
    "                score = results_summary[sample_name][model_name][metric]\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_combo = (sample_name, model_name, score)\n",
    "    \n",
    "    if best_combo:\n",
    "        print(f\"  Sampling: {best_combo[0]}\")\n",
    "        print(f\"  Model: {best_combo[1]}\")\n",
    "        print(f\"  Score: {best_combo[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
